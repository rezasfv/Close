\newpage
\enlargethispage{3\baselineskip}
\section{Experimental Setup}
\label{sec:setup}

\subsection{Collections}
We developed our model using a collection of 1,593,376 documents and 882 queries provided by \textit{Qwant} search engine, available at \url{https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-5010}.
\newline
The collection contains information about user web searches and actual web pages corpora. The data was originally all in French but, for both queries and documents, an English translation is provided.


\subsection{Evaluation Measures}
To measure the effectiveness of our \ac{IR} system we used the \textit{trec\_eval} executable by testing it with the resulting runs produced by the model and its different configurations.
\newline
We tracked improvements of the following evaluation measures generated by \textit{trec\_eval}:
\begin{itemize}
	\item \textbf{num\textunderscore ret}: number of documents retrieved for a given query.
	\item \textbf{num\textunderscore rel}: number of relevant documents for a given query.
	\item \textbf{num \textunderscore rel\textunderscore ret}: number of relevant documents retrieved for a given query.
    \item \textbf{map}: Mean Average Precision, a measure of the average relevance of retrieved documents across all queries. Its range is in 0-1, where 1 indicates that all relevant documents are ranked at the top of the result list.
    \newline
    It's calculated as follows:
    \begin{equation*}
        MAP = \frac{1}{N} \sum_{i=1}^{N}AP_i
    \end{equation*}
    where $N$ is the total number of queries and $AP_i$ is the average precision of $query_i$ and calculated as:
    \begin{equation*}
        AP = \frac{1}{RD} \sum_{k=1}^{n}P(k)r(k)
    \end{equation*}
    with $RD$ the number of relevant documents for the query, $n$ the number of total documents, $P(k)$ the precision at $k$ and $r(k)$ the relevance of the $k$th retrieved document (0 if not relevant, 1 otherwise).
    \newline
    A high \ac{MAP} score indicates that the model effectively retrieves relevant documents for a wide range of queries.
    \item \textbf{rprec}: R-Precision is the precision score computed at the rank corresponding to the number of relevant documents for a given query.
    \item \textbf{p@5} and \textbf{p@10}: Precision at 5 and at 10 is the precision computed at the top 5 and 10 retrieved documents for a given query.
    They are calculated as follows:
    \begin{equation*}
        P(5) = \frac{1}{5} \sum_{k=1}^{5}r(k) \qquad ; \qquad P(10) = \frac{1}{10} \sum_{k=1}^{10}r(k)
    \end{equation*}
    with $r(k)$ the relevance of the $k$th document.
    \newline
    These two values can be useful to understand if the system retrieves relevant documents early in the result list, making it easier for the user to find the information needed.

\end{itemize}

\newpage
\subsection{Git Repository}
The \textit{git} repository of the project can be found at
\url{https://bitbucket.org/upd-dei-stud-prj/seupd2223-close/src/master/} and it is organized as follows:
\dirtree{%
.1 \textbf{/}.
.2 code/.
.3 src/main/.
.4 java/it/unipd/dei/se/.
.5 analyzer.
.5 indexer.
.5 parser.
.5 searcher.
.5 utils   <-- ReRanker and array converter util.
.5 \textit{CloseSearchEngine.java}   <-- main class.
.4 resources   <-- word stoplists and models for NER and POS.
.3 python\textunderscore scripts   <-- python scripts, results for embeddings, ....
.3 \textit{pom.xml}.
.2 runs   <-- run files.
.2 results   <-- result files.
}


\subsection{System Hardware}
For the most time during the development of the system every member of the group ran the model on its own system, but after implementing the deep learning techniques we decided to switch and start running the tasks using GPU to improve time performances. \\
The following are the specifics of the machines used after switching to computing also with GPU:
\begin{itemize}
	\item CPU: Intel® Core™ i9-12900H 12th generation
	\item GPU: NVIDIA RTX™ A 2000 4GB GDDR6
	\item RAM: 16 GB SO-DIMM DDR5 4800MHz
	\item SSD: 512 GB M.2 2280 PCIe Gen4 TLC Opal
\end{itemize}
\begin{itemize}
	\item CPU: Ryzen 7 1700 overclocked at 3.8GHz
	\item GPU: RTX 3070 TI 8GB GDDR6X
	\item RAM: 16GB  DDR4 3000MHz
	\item SSD: Samsung evo 970 250GB
\end{itemize}


